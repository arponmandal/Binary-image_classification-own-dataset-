{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary image_classification - Happy or Sad Dataset(or own dataset).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4hNjbg2v0KAUmxuaGMz3L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arponmandal/Binary-image_classification-own-dataset-/blob/main/Binary_image_classification_Happy_or_Sad_Dataset(or_own_dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9IieiNx-YTc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin by taking a look at some images of the dataset:"
      ],
      "metadata": {
        "id": "HukA_S79--HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "happy_dir = \"./data/happy/\"\n",
        "sad_dir = \"./data/sad/\"\n",
        "\n",
        "print(\"Sample happy image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\"))\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSample sad image:\")\n",
        "plt.imshow(load_img(f\"{os.path.join(sad_dir, os.listdir(sad_dir)[0])}\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SCInWYSh_EOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Load the first example of a happy face\n",
        "sample_image  = load_img(f\"{os.path.join(happy_dir, os.listdir(happy_dir)[0])}\")\n",
        "\n",
        "# Convert the image into its numpy array representation\n",
        "sample_array = img_to_array(sample_image)\n",
        "\n",
        "print(f\"Each image has shape: {sample_array.shape}\")\n",
        "\n",
        "print(f\"The maximum pixel value used is: {np.max(sample_array)}\")"
      ],
      "metadata": {
        "id": "8PF0ilpU_H0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like the images have a resolution of 150x150. This is very important because this will be the input size of the first layer in your network.\n",
        "\n",
        "The last dimension refers to each one of the 3 RGB channels that are used to represent colored images.\n"
      ],
      "metadata": {
        "id": "OsCNIIaT_SOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.999:\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "MM0AKsdu_M1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# GRADED FUNCTION: image_generator\n",
        "def image_generator():\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class.\n",
        "    # Remember to set the rescale argument.\n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    # Specify the method to load images from a directory and pass in the appropriate arguments:\n",
        "    # - directory: should be a relative path to the directory containing the data\n",
        "    # - targe_size: set this equal to the resolution of each image (excluding the color dimension)\n",
        "    # - batch_size: number of images the generator yields when asked for a next batch. Set this to 10.\n",
        "    # - class_mode: How the labels are represented. Should be one of \"binary\", \"categorical\" or \"sparse\".\n",
        "    #               Pick the one that better suits here given that the labels are going to be 1D binary labels.\n",
        "    train_generator = train_datagen.flow_from_directory(directory='./data/',\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=10,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "    return train_generator"
      ],
      "metadata": {
        "id": "U_UZu5vz_2xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your generator in a variable\n",
        "gen = image_generator()\n",
        "\n",
        "# Expected output: 'Found 80 images belonging to 2 classes'"
      ],
      "metadata": {
        "id": "mkJxwSHJACHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_happy_sad_model(train_generator):\n",
        "\n",
        "    # Instantiate the callback\n",
        "    callbacks = myCallback()\n",
        "\n",
        "    # Define the model, you can toy around with the architecture.\n",
        "    # Some helpful tips in case you are stuck:\n",
        "    \n",
        "    # - A good first layer would be a Conv2D layer with an input shape that matches \n",
        "    #   that of every image in the training set (including the color dimension)\n",
        "\n",
        "    # - The model will work best with 3 convolutional layers\n",
        "\n",
        "    # - There should be a Flatten layer in between convolutional and dense layers\n",
        "\n",
        "    # - The final layer should be a Dense layer with the number of units \n",
        "    #   and activation function that supports binary classification.\n",
        "\n",
        "    model = tf.keras.models.Sequential([ \n",
        "        # First convolution\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        # Second convolution\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        # Third convolution\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        # Flatten\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # Dense layers\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    # Select a loss function compatible with the last layer of your network\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
        "                  metrics=['accuracy']) \n",
        "    \n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    # Your model should achieve the desired accuracy in less than 15 epochs.\n",
        "    # You can hardcode up to 20 epochs in the function below but the callback should trigger before 15.\n",
        "    history = model.fit(train_generator,\n",
        "                        epochs=20,\n",
        "                        callbacks=[callbacks]\n",
        "                       ) \n",
        "    return history"
      ],
      "metadata": {
        "id": "4lAtH6LvAL6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = train_happy_sad_model(gen)"
      ],
      "metadata": {
        "id": "0WENx3b3Aezp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Your model reached the desired accuracy after {len(hist.epoch)} epochs\")\n"
      ],
      "metadata": {
        "id": "I4HF80qGA6Ov"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}